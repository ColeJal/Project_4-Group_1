{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "8f965746",
      "metadata": {
        "id": "8f965746"
      },
      "outputs": [],
      "source": [
        "# import required libraries\n",
        "import nltk\n",
        "from nltk import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import pandas as pd\n",
        "import string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "98da782e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98da782e",
        "outputId": "6ebc5fee-3663-4ac7-a9ff-55371a512938"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "# download punctuation and stopwords from nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "wJuTq-P9LO38",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJuTq-P9LO38",
        "outputId": "2eb296a6-7d4a-4690-b2f6-d420d0192cec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Hit:2 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:3 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Ign:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease [1,581 B]\n",
            "Hit:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Hit:8 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Get:9 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [1,039 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [83.3 kB]\n",
            "Hit:11 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:13 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Get:14 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [3,094 kB]\n",
            "Get:15 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease [21.3 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [3,519 kB]\n",
            "Get:17 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic/main amd64 Packages [38.5 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [1,334 kB]\n",
            "Get:19 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,568 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,342 kB]\n",
            "Get:21 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [1,294 kB]\n",
            "Fetched 14.5 MB in 18s (822 kB/s)\n",
            "Reading package lists... Done\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "# Find the latest version of spark 3.2  from http://www.apache.org/dist/spark/ and enter as the spark version\n",
        "# For example:\n",
        "spark_version = 'spark-3.2.3'\n",
        "# spark_version = 'spark-3.<enter version>'\n",
        "os.environ['SPARK_VERSION']=spark_version\n",
        "\n",
        "# Install Spark and Java\n",
        "!apt-get update\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q http://www.apache.org/dist/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop2.7.tgz\n",
        "!tar xf $SPARK_VERSION-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark\n",
        "\n",
        "# Set Environment Variables\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = f\"/content/{spark_version}-bin-hadoop2.7\"\n",
        "\n",
        "# Start a SparkSession\n",
        "import findspark\n",
        "findspark.init()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4c986391",
      "metadata": {
        "id": "4c986391"
      },
      "source": [
        "# Transform the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "c503a564",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "c503a564",
        "outputId": "41394f1b-1e83-4e1a-f887-fa510609907b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           textID                                               text  \\\n",
              "0      cb774db0d1                I`d have responded, if I were going   \n",
              "1      549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
              "2      088c60f138                          my boss is bullying me...   \n",
              "3      9642c003ef                     what interview! leave me alone   \n",
              "4      358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
              "...           ...                                                ...   \n",
              "16438  cfab7a12da           Sounds lovely, hope you have a great day   \n",
              "16439  3e90b21788                                     you`re welcome   \n",
              "16440  8a1f99c790  _1988 cool i wish i could av gone 2 da 1 he di...   \n",
              "16441  fea9c59435  i miss justin timberlake`s voice. i want him t...   \n",
              "16442  11bdda3f0f   wow!! you really are a pretty talented lady, ...   \n",
              "\n",
              "                             selected_text sentiment  \n",
              "0      I`d have responded, if I were going   neutral  \n",
              "1                                 Sooo SAD  negative  \n",
              "2                              bullying me  negative  \n",
              "3                           leave me alone  negative  \n",
              "4                            Sons of ****,  negative  \n",
              "...                                    ...       ...  \n",
              "16438                       Sounds lovely,  positive  \n",
              "16439                       you`re welcome   neutral  \n",
              "16440                        but i couldnt  negative  \n",
              "16441                               i miss  negative  \n",
              "16442                             talented     posit  \n",
              "\n",
              "[16443 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f05d821e-5745-4ecc-9e13-413c2ba53a15\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>textID</th>\n",
              "      <th>text</th>\n",
              "      <th>selected_text</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>cb774db0d1</td>\n",
              "      <td>I`d have responded, if I were going</td>\n",
              "      <td>I`d have responded, if I were going</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>549e992a42</td>\n",
              "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
              "      <td>Sooo SAD</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>088c60f138</td>\n",
              "      <td>my boss is bullying me...</td>\n",
              "      <td>bullying me</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9642c003ef</td>\n",
              "      <td>what interview! leave me alone</td>\n",
              "      <td>leave me alone</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>358bd9e861</td>\n",
              "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
              "      <td>Sons of ****,</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16438</th>\n",
              "      <td>cfab7a12da</td>\n",
              "      <td>Sounds lovely, hope you have a great day</td>\n",
              "      <td>Sounds lovely,</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16439</th>\n",
              "      <td>3e90b21788</td>\n",
              "      <td>you`re welcome</td>\n",
              "      <td>you`re welcome</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16440</th>\n",
              "      <td>8a1f99c790</td>\n",
              "      <td>_1988 cool i wish i could av gone 2 da 1 he di...</td>\n",
              "      <td>but i couldnt</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16441</th>\n",
              "      <td>fea9c59435</td>\n",
              "      <td>i miss justin timberlake`s voice. i want him t...</td>\n",
              "      <td>i miss</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16442</th>\n",
              "      <td>11bdda3f0f</td>\n",
              "      <td>wow!! you really are a pretty talented lady, ...</td>\n",
              "      <td>talented</td>\n",
              "      <td>posit</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>16443 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f05d821e-5745-4ecc-9e13-413c2ba53a15')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f05d821e-5745-4ecc-9e13-413c2ba53a15 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f05d821e-5745-4ecc-9e13-413c2ba53a15');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# load tweets_df and view\n",
        "# tweets_df = pd.read_csv(\"Resources/Tweets.csv\")\n",
        "\n",
        "\n",
        "\n",
        "from pyspark import SparkFiles\n",
        "# url =\"https://tweet-2022.s3.amazonaws.com/Tweets.csv\"\n",
        "# spark.sparkContext.addFile(url)\n",
        "# spark_tweets_df = spark.read.csv(SparkFiles.get(\"Tweets.csv\"), sep=\",\", header=True)\n",
        "# tweets_df = spark.read.csv(SparkFiles.get(\"Tweets.csv\"), sep=\",\", header=True)\n",
        "\n",
        "\n",
        "tweets_df = pd.read_csv(\"/content/Tweets.csv\")\n",
        "# tweets_df=spark_tweets_df.toPandas()\n",
        "tweets_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "c311757b",
      "metadata": {
        "id": "c311757b"
      },
      "outputs": [],
      "source": [
        "# get dataframe ready for processing\n",
        "\n",
        "# make sure the tweets in column \"text\" are strings\n",
        "tweets_df['text'] = tweets_df['text'].astype('str')\n",
        "\n",
        "# delete the unneccessary columns\n",
        "tweets_df = tweets_df.drop(columns=[\"textID\", \"selected_text\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "47021da3",
      "metadata": {
        "id": "47021da3"
      },
      "outputs": [],
      "source": [
        "def process_tweets(tweet):\n",
        "    # make the text all lowercase\n",
        "    tweet = tweet.lower()\n",
        "    \n",
        "    # remove punctuation\n",
        "    tweet = \"\".join(char for char in tweet if char not in string.punctuation)\n",
        "    \n",
        "    # tokenize the tweet for url clean\n",
        "    tokenize_tweet_url = word_tokenize(tweet)\n",
        "    \n",
        "    # remove urls\n",
        "    tokenize_tweet_url = \" \".join([i for i in tokenize_tweet_url if 'http' not in i])\n",
        "    \n",
        "    # tokenize the tweet\n",
        "    tokenize_tweets = word_tokenize(tokenize_tweet_url)\n",
        "    \n",
        "    # remove stopwords\n",
        "    stopword = stopwords.words(\"english\")\n",
        "    tweet_wo_stop = [word for word in tokenize_tweets if word not in stopword]\n",
        "    \n",
        "    # lemmatization\n",
        "    lemm = WordNetLemmatizer()\n",
        "    lemmed = [lemm.lemmatize(word) for word in tweet_wo_stop]\n",
        "    \n",
        "    # put string together\n",
        "    final_tweet = \" \".join(lemmed)\n",
        "    \n",
        "    return final_tweet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "8616da88",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "8616da88",
        "outputId": "c5eeadee-15ae-43ac-d81e-63e5c8bd5408"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                     text sentiment\n",
              "0                      id responded going   neutral\n",
              "1                 sooo sad miss san diego  negative\n",
              "2                            bos bullying  negative\n",
              "3                   interview leave alone  negative\n",
              "4  son couldnt put release already bought  negative"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7acc593e-9a5f-4c80-91e9-fba0e346d72c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>id responded going</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>sooo sad miss san diego</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>bos bullying</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>interview leave alone</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>son couldnt put release already bought</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7acc593e-9a5f-4c80-91e9-fba0e346d72c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7acc593e-9a5f-4c80-91e9-fba0e346d72c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7acc593e-9a5f-4c80-91e9-fba0e346d72c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# process tweets using above function\n",
        "tweets_df['text'] = tweets_df['text'].apply(lambda x: process_tweets(x))\n",
        "tweets_df = tweets_df.dropna()\n",
        "\n",
        "# view updated dataframe\n",
        "tweets_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "f2da464f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "f2da464f",
        "outputId": "0bebd6af-f8d0-4156-890b-c86ee4dae3f1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f7604a95370>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# visualize distribution\n",
        "tweets_df.sentiment.value_counts().plot(kind='pie', autopct='%1.0f%%', colors=['blue', 'gold', 'red'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "aa959b52",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "aa959b52",
        "outputId": "b4e37608-0473-4f21-93c5-e551d76edb7e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                     text  sentiment\n",
              "0                      id responded going        0.0\n",
              "1                 sooo sad miss san diego       -1.0\n",
              "2                            bos bullying       -1.0\n",
              "3                   interview leave alone       -1.0\n",
              "4  son couldnt put release already bought       -1.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-026934d4-e36a-4c5d-aec8-308f869a557b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>id responded going</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>sooo sad miss san diego</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>bos bullying</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>interview leave alone</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>son couldnt put release already bought</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-026934d4-e36a-4c5d-aec8-308f869a557b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-026934d4-e36a-4c5d-aec8-308f869a557b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-026934d4-e36a-4c5d-aec8-308f869a557b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# transform the sentiment column into numbers\n",
        "dict_sentiment = {'positive': 1, 'neutral': 0, 'negative': -1}\n",
        "tweets_df['sentiment'] = tweets_df['sentiment'].apply(lambda x: dict_sentiment.get(x))\n",
        "\n",
        "# view updated dataframe\n",
        "tweets_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c926d3e2",
      "metadata": {
        "id": "c926d3e2"
      },
      "outputs": [],
      "source": [
        "# create a separate data frame without neutral tweets\n",
        "tweets_no_neut = tweets_df[tweets_df[\"sentiment\"] != 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f0280c2",
      "metadata": {
        "id": "7f0280c2"
      },
      "outputs": [],
      "source": [
        "# Create the X and y data \n",
        "def create_train_test_data (tweets_df, train_size):\n",
        "    \n",
        "    # assign X and y to the input and target columns\n",
        "    X = tweets_df['text']\n",
        "    y = tweets_df['sentiment']\n",
        "\n",
        "    # split the data into testing data and training data\n",
        "    if train_size == 0:\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
        "    else:\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=train_size)\n",
        "\n",
        "    # transform the data into tfidf vectors\n",
        "    # fit the tfidf vectorizer on the training data to avoid bias\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "    X_test_tfidf = vectorizer.transform(X_test)\n",
        "    \n",
        "    return X_train_tfidf, X_test_tfidf, y_train, y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "91767a3f",
      "metadata": {
        "id": "91767a3f"
      },
      "outputs": [],
      "source": [
        "# create the model\n",
        "def create_model(tweets_df, attempt_num, model, train_size):\n",
        "    # Get the train and test data\n",
        "    \n",
        "    X_train_tfidf, X_test_tfidf, y_train, y_test = create_train_test_data (tweets_df, train_size)\n",
        "\n",
        "    # create a logistic regression model and fit it to the training data\n",
        "    \n",
        "    model.fit(X_train_tfidf, y_train)\n",
        "    evaluate(model, X_train_tfidf, y_train, X_test_tfidf, y_test, attempt_num)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0219b4d8",
      "metadata": {
        "id": "0219b4d8"
      },
      "outputs": [],
      "source": [
        "# evaluate the model\n",
        "def evaluate(model, X_train_tfidf, y_train, X_test_tfidf, y_test, attempt_num):\n",
        "    \n",
        "    # look at the scores for the testing and training data\n",
        "    print(f\"Attempt {attempt_num} ----------------------------------------\")\n",
        "    print(f\"Training Data Score: {model.score(X_train_tfidf, y_train)}\")\n",
        "    print(f\"Testing Data Score: {model.score(X_test_tfidf, y_test)} \\n\")\n",
        "\n",
        "    # find metrics for testing data\n",
        "    print(confusion_matrix(y_test.values, model.predict(X_test_tfidf)))\n",
        "    print(classification_report(y_test.values, model.predict(X_test_tfidf)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7252b265",
      "metadata": {
        "id": "7252b265"
      },
      "source": [
        "## Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c056cb6b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c056cb6b",
        "outputId": "c93e9f3c-8dec-485d-ff33-d3a3f097ae56"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Attempt 1 ----------------------------------------\n",
            "Training Data Score: 0.8200873362445414\n",
            "Testing Data Score: 0.6962596419735119 \n",
            "\n",
            "[[1179  675  112]\n",
            " [ 328 2117  343]\n",
            " [  74  555 1488]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.75      0.60      0.66      1966\n",
            "           0       0.63      0.76      0.69      2788\n",
            "           1       0.77      0.70      0.73      2117\n",
            "\n",
            "    accuracy                           0.70      6871\n",
            "   macro avg       0.71      0.69      0.70      6871\n",
            "weighted avg       0.71      0.70      0.70      6871\n",
            "\n",
            "Attempt 2 ----------------------------------------\n",
            "Training Data Score: 0.929351368970013\n",
            "Testing Data Score: 0.8724028354925446 \n",
            "\n",
            "[[1674  247]\n",
            " [ 275 1895]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.86      0.87      0.87      1921\n",
            "           1       0.88      0.87      0.88      2170\n",
            "\n",
            "    accuracy                           0.87      4091\n",
            "   macro avg       0.87      0.87      0.87      4091\n",
            "weighted avg       0.87      0.87      0.87      4091\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "model = LogisticRegression()\n",
        "create_model(tweets_df, 1, model, 0)\n",
        "create_model(tweets_no_neut, 2, model, 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b194d5d2",
      "metadata": {
        "id": "b194d5d2"
      },
      "source": [
        "## Random Forest Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31875fa3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31875fa3",
        "outputId": "d0bb9b80-6600-440b-8ad5-d403d1d33fc8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Attempt 1 ----------------------------------------\n",
            "Training Data Score: 0.9975891557496361\n",
            "Testing Data Score: 0.6941968346370748 \n",
            "\n",
            "[[ 902  500  114]\n",
            " [ 272 1669  332]\n",
            " [  69  394 1245]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.73      0.59      0.65      1516\n",
            "           0       0.65      0.73      0.69      2273\n",
            "           1       0.74      0.73      0.73      1708\n",
            "\n",
            "    accuracy                           0.69      5497\n",
            "   macro avg       0.70      0.69      0.69      5497\n",
            "weighted avg       0.70      0.69      0.69      5497\n",
            "\n",
            "Attempt 2 ----------------------------------------\n",
            "Training Data Score: 0.9995416348357525\n",
            "Testing Data Score: 0.8643446379468378 \n",
            "\n",
            "[[1375  221]\n",
            " [ 223 1454]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.86      0.86      0.86      1596\n",
            "           1       0.87      0.87      0.87      1677\n",
            "\n",
            "    accuracy                           0.86      3273\n",
            "   macro avg       0.86      0.86      0.86      3273\n",
            "weighted avg       0.86      0.86      0.86      3273\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "twitter_classi = RandomForestClassifier(n_estimators=300, random_state=0)\n",
        "create_model(tweets_df, 1, twitter_classi, train_size=.8)\n",
        "create_model(tweets_no_neut, 2, twitter_classi, train_size=.8)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a107093b",
      "metadata": {
        "id": "a107093b"
      },
      "source": [
        "## Extra Trees Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1559f69",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1559f69",
        "outputId": "015f9482-486d-4f76-98a9-a9da6d6baa6f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Attempt 1 ----------------------------------------\n",
            "Training Data Score: 0.9975891557496361\n",
            "Testing Data Score: 0.6994724395124613 \n",
            "\n",
            "[[ 936  475  117]\n",
            " [ 320 1565  330]\n",
            " [  63  347 1344]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.71      0.61      0.66      1528\n",
            "           0       0.66      0.71      0.68      2215\n",
            "           1       0.75      0.77      0.76      1754\n",
            "\n",
            "    accuracy                           0.70      5497\n",
            "   macro avg       0.71      0.70      0.70      5497\n",
            "weighted avg       0.70      0.70      0.70      5497\n",
            "\n",
            "Attempt 2 ----------------------------------------\n",
            "Training Data Score: 0.9995416348357525\n",
            "Testing Data Score: 0.8579285059578369 \n",
            "\n",
            "[[1346  204]\n",
            " [ 261 1462]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.84      0.87      0.85      1550\n",
            "           1       0.88      0.85      0.86      1723\n",
            "\n",
            "    accuracy                           0.86      3273\n",
            "   macro avg       0.86      0.86      0.86      3273\n",
            "weighted avg       0.86      0.86      0.86      3273\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "\n",
        "twitter_ex = ExtraTreesClassifier(random_state=1)\n",
        "create_model(tweets_df, 1, twitter_ex, train_size=.8)\n",
        "create_model(tweets_no_neut, 2, twitter_ex, train_size=.8)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0002db64",
      "metadata": {
        "id": "0002db64"
      },
      "source": [
        "## Ada Boost Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "772d9f0b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "772d9f0b",
        "outputId": "daa43f4d-b2d0-4177-96e5-d829a7912feb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Attempt 1 ----------------------------------------\n",
            "Training Data Score: 0.6543850072780204\n",
            "Testing Data Score: 0.665999636165181 \n",
            "\n",
            "[[ 641  782  110]\n",
            " [ 185 1855  252]\n",
            " [  44  463 1165]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.74      0.42      0.53      1533\n",
            "           0       0.60      0.81      0.69      2292\n",
            "           1       0.76      0.70      0.73      1672\n",
            "\n",
            "    accuracy                           0.67      5497\n",
            "   macro avg       0.70      0.64      0.65      5497\n",
            "weighted avg       0.69      0.67      0.66      5497\n",
            "\n",
            "Attempt 2 ----------------------------------------\n",
            "Training Data Score: 0.8083269671504966\n",
            "Testing Data Score: 0.8041552092881149 \n",
            "\n",
            "[[1418  145]\n",
            " [ 496 1214]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.74      0.91      0.82      1563\n",
            "           1       0.89      0.71      0.79      1710\n",
            "\n",
            "    accuracy                           0.80      3273\n",
            "   macro avg       0.82      0.81      0.80      3273\n",
            "weighted avg       0.82      0.80      0.80      3273\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "twitter_ada = AdaBoostClassifier(random_state=1)\n",
        "create_model(tweets_df, 1, twitter_ada, train_size=.8)\n",
        "create_model(tweets_no_neut, 2, twitter_ada, train_size=.8)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a25a8104",
      "metadata": {
        "id": "a25a8104"
      },
      "source": [
        "# Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8dfd0224",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8dfd0224",
        "outputId": "55ad0d56-b8cb-4200-b9f7-253dd8b2d0f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Attempt 1 ----------------------------------------\n",
            "Training Data Score: 0.7995360262008734\n",
            "Testing Data Score: 0.6243405493905767 \n",
            "\n",
            "[[ 636  839   70]\n",
            " [ 159 1853  270]\n",
            " [  18  709  943]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.78      0.41      0.54      1545\n",
            "           0       0.54      0.81      0.65      2282\n",
            "           1       0.73      0.56      0.64      1670\n",
            "\n",
            "    accuracy                           0.62      5497\n",
            "   macro avg       0.69      0.60      0.61      5497\n",
            "weighted avg       0.67      0.62      0.62      5497\n",
            "\n",
            "Attempt 2 ----------------------------------------\n",
            "Training Data Score: 0.9420932009167303\n",
            "Testing Data Score: 0.846012832263978 \n",
            "\n",
            "[[1273  305]\n",
            " [ 199 1496]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.86      0.81      0.83      1578\n",
            "           1       0.83      0.88      0.86      1695\n",
            "\n",
            "    accuracy                           0.85      3273\n",
            "   macro avg       0.85      0.84      0.85      3273\n",
            "weighted avg       0.85      0.85      0.85      3273\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "mnb = MultinomialNB()\n",
        "create_model(tweets_df,1,mnb,train_size=0.8)\n",
        "create_model(tweets_no_neut,2,mnb,train_size=0.8)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1eg0eqPOllG0",
      "metadata": {
        "id": "1eg0eqPOllG0"
      },
      "source": [
        "# Naive Bayes using PySpark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "Sh4IFN6tL7DS",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 502
        },
        "id": "Sh4IFN6tL7DS",
        "outputId": "8696a9a2-b6e3-4487-f44d-88d474d22d26"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           textID                                               text  \\\n",
              "0      cb774db0d1                I`d have responded, if I were going   \n",
              "1      549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
              "2      088c60f138                          my boss is bullying me...   \n",
              "3      9642c003ef                     what interview! leave me alone   \n",
              "4      358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
              "...           ...                                                ...   \n",
              "27476  4eac33d1c0   wish we could come see u on Denver  husband l...   \n",
              "27477  4f4c4fc327   I`ve wondered about rake to.  The client has ...   \n",
              "27478  f67aae2310   Yay good for both of you. Enjoy the break - y...   \n",
              "27479  ed167662a5                         But it was worth it  ****.   \n",
              "27480  6f7127d9d7     All this flirting going on - The ATG smiles...   \n",
              "\n",
              "                                           selected_text sentiment  \n",
              "0                    I`d have responded, if I were going   neutral  \n",
              "1                                               Sooo SAD  negative  \n",
              "2                                            bullying me  negative  \n",
              "3                                         leave me alone  negative  \n",
              "4                                          Sons of ****,  negative  \n",
              "...                                                  ...       ...  \n",
              "27476                                             d lost  negative  \n",
              "27477                                      , don`t force  negative  \n",
              "27478                          Yay good for both of you.  positive  \n",
              "27479                         But it was worth it  ****.  positive  \n",
              "27480  All this flirting going on - The ATG smiles. Y...   neutral  \n",
              "\n",
              "[27481 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fcdec8ed-4b98-43a9-8eee-2d372b8d996b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>textID</th>\n",
              "      <th>text</th>\n",
              "      <th>selected_text</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>cb774db0d1</td>\n",
              "      <td>I`d have responded, if I were going</td>\n",
              "      <td>I`d have responded, if I were going</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>549e992a42</td>\n",
              "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
              "      <td>Sooo SAD</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>088c60f138</td>\n",
              "      <td>my boss is bullying me...</td>\n",
              "      <td>bullying me</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9642c003ef</td>\n",
              "      <td>what interview! leave me alone</td>\n",
              "      <td>leave me alone</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>358bd9e861</td>\n",
              "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
              "      <td>Sons of ****,</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27476</th>\n",
              "      <td>4eac33d1c0</td>\n",
              "      <td>wish we could come see u on Denver  husband l...</td>\n",
              "      <td>d lost</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27477</th>\n",
              "      <td>4f4c4fc327</td>\n",
              "      <td>I`ve wondered about rake to.  The client has ...</td>\n",
              "      <td>, don`t force</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27478</th>\n",
              "      <td>f67aae2310</td>\n",
              "      <td>Yay good for both of you. Enjoy the break - y...</td>\n",
              "      <td>Yay good for both of you.</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27479</th>\n",
              "      <td>ed167662a5</td>\n",
              "      <td>But it was worth it  ****.</td>\n",
              "      <td>But it was worth it  ****.</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27480</th>\n",
              "      <td>6f7127d9d7</td>\n",
              "      <td>All this flirting going on - The ATG smiles...</td>\n",
              "      <td>All this flirting going on - The ATG smiles. Y...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>27481 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fcdec8ed-4b98-43a9-8eee-2d372b8d996b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fcdec8ed-4b98-43a9-8eee-2d372b8d996b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fcdec8ed-4b98-43a9-8eee-2d372b8d996b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"NaiveBayes\").getOrCreate()\n",
        "# url =\"https://tweet-2022.s3.amazonaws.com/Tweets.csv\"\n",
        "# spark.sparkContext.addFile(url)\n",
        "# spark_tweets_df = spark.read.csv(SparkFiles.get(\"Tweets.csv\"), sep=\",\", header=True)\n",
        "# tweets_df = spark.read.csv(SparkFiles.get(\"Tweets.csv\"), sep=\",\", header=True)\n",
        "\n",
        "\n",
        "nb_tweets_df = pd.read_csv(\"/content/Tweets.csv\")\n",
        "# tweets_df=spark_tweets_df.toPandas()\n",
        "nb_tweets_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "l3Gb21sVSjCs",
      "metadata": {
        "id": "l3Gb21sVSjCs"
      },
      "outputs": [],
      "source": [
        "def nb_process_tweets(tweet):\n",
        "    # make the text all lowercase\n",
        "    tweet = tweet.lower()\n",
        "    \n",
        "    # remove punctuation\n",
        "    tweet = \"\".join(char for char in tweet if char not in string.punctuation)\n",
        "  \n",
        "    # remove urls\n",
        "    tweet_wo_stop = \"\".join([i for i in tweet if 'http' not in i])\n",
        "    \n",
        "    \n",
        "    # lemmatization\n",
        "    lemm = WordNetLemmatizer()\n",
        "    lemmed = [lemm.lemmatize(word) for word in tweet_wo_stop]\n",
        "    \n",
        "    # put string together\n",
        "    final_tweet = \"\".join(lemmed)\n",
        "    \n",
        "    return final_tweet\n",
        "nb_tweets_df['text'] = nb_tweets_df['text'].astype('str')\n",
        "\n",
        "# delete the unneccessary columns\n",
        "nb_tweets_df = nb_tweets_df.drop(columns=[\"textID\", \"selected_text\"])\n",
        "nb_tweets_df=nb_tweets_df.rename(columns={'sentiment':'class'})\n",
        "nb_tweets_df=nb_tweets_df[['class','text']]\n",
        "nb_tweets_df['text'] = nb_tweets_df['text'].apply(lambda x: nb_process_tweets(x))\n",
        "\n",
        "\n",
        "nb_opt=nb_tweets_df.loc[nb_tweets_df['class']!=\"neutral\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68yRlnxfVV14",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68yRlnxfVV14",
        "outputId": "c85c5f8b-1b39-4760-a9a8-6a909b808044"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting quinn\n",
            "  Downloading quinn-0.9.0-py2.py3-none-any.whl (9.3 kB)\n",
            "Installing collected packages: quinn\n",
            "Successfully installed quinn-0.9.0\n"
          ]
        }
      ],
      "source": [
        "pip install quinn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.ml.classification import NaiveBayes"
      ],
      "metadata": {
        "id": "pFPaG4O_Zc16"
      },
      "id": "pFPaG4O_Zc16",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "2mJ0-r_6fr2w",
      "metadata": {
        "id": "2mJ0-r_6fr2w"
      },
      "outputs": [],
      "source": [
        "def create_nb(tweets_df,attempt_num,model,train_size):\n",
        "  from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF, StringIndexer\n",
        "# Create all the features to the data set\n",
        "  pos_neg_to_num = StringIndexer(inputCol='class',outputCol='label')\n",
        "  tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"token_text\")\n",
        "  stopremove = StopWordsRemover(inputCol='token_text',outputCol='stop_tokens')\n",
        "  hashingTF = HashingTF(inputCol=\"stop_tokens\", outputCol='hash_token')\n",
        "  idf = IDF(inputCol='hash_token', outputCol='idf_token')\n",
        "  from pyspark.ml.feature import VectorAssembler\n",
        "  from pyspark.ml.linalg import Vector\n",
        "\n",
        "  # Create feature vectors\n",
        "  clean_up = VectorAssembler(inputCols=['idf_token', 'length'], outputCol='features')\n",
        "  from pyspark.ml import Pipeline\n",
        "  data_prep_pipeline = Pipeline(stages=[pos_neg_to_num, tokenizer, stopremove, hashingTF, idf, clean_up])\n",
        "  from pyspark.sql import SQLContext\n",
        "  sc = SparkSession.builder.getOrCreate()\n",
        "  sqlContext = SQLContext(sc)\n",
        "  spark_tweets = sqlContext.createDataFrame(tweets_df)\n",
        "\n",
        "\n",
        "\n",
        "  import quinn\n",
        "  trimmed=spark_tweets.withColumn('description',quinn.single_space(spark_tweets['text']))\n",
        "  trimmed=trimmed.select('class','description')\n",
        "  trimmed=trimmed.withColumnRenamed('description','text')\n",
        "  trimmed=trimmed.toPandas()\n",
        "  trimmed['length']=\"\"\n",
        "  for index,row in trimmed.iterrows():\n",
        "    nb_tweet_length=len(row['text'])\n",
        "    trimmed.loc[index,'length']=nb_tweet_length\n",
        "  trimmed_spark=sqlContext.createDataFrame(trimmed)\n",
        "  cleaner = data_prep_pipeline.fit(trimmed_spark)\n",
        "  cleaned = cleaner.transform(trimmed_spark)\n",
        "\n",
        "  # cleaner = data_prep_pipeline.fit(spark_tweets)\n",
        "  # cleaned = cleaner.transform(spark_tweets)\n",
        "  \n",
        "  # Break data down into a training set and a testing set\n",
        "  # training, testing = cleaned.randomSplit([0.7, 0.3])\n",
        "  training, testing = cleaned.randomSplit([train_size, 1-train_size])\n",
        "  predictor = nb.fit(training)\n",
        "  \n",
        "  test_results = predictor.transform(testing)\n",
        "  acc_eval = MulticlassClassificationEvaluator(labelCol=\"label\",predictionCol=\"prediction\")\n",
        "  acc = acc_eval.evaluate(test_results)\n",
        "  predictionAndTarget = test_results.select(\"label\", \"prediction\")\n",
        "\n",
        "  # Get metrics\n",
        "  # train_acc=acc_eval(predictor.transform(testing).select('label','prediction'))\n",
        "  acc = acc_eval.evaluate(predictionAndTarget, {acc_eval.metricName: \"accuracy\"})\n",
        "  f1 = acc_eval.evaluate(predictionAndTarget, {acc_eval.metricName: \"f1\"})\n",
        "  weightedPrecision = acc_eval.evaluate(predictionAndTarget, {acc_eval.metricName: \"weightedPrecision\"})\n",
        "  weightedRecall = acc_eval.evaluate(predictionAndTarget, {acc_eval.metricName: \"weightedRecall\"})\n",
        "  auc = acc_eval.evaluate(predictionAndTarget)\n",
        "  # print(f\"Training Accuracy of model: {train_acc}\")\n",
        "  print(f\"Testing Accuracy of model: {acc}\")\n",
        "  print(f\"Precision of model: {weightedPrecision}\")\n",
        "  print(f\"Recall of model:{weightedRecall}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "k51XMckkgXQt",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "k51XMckkgXQt",
        "outputId": "fd6a590d-586c-453e-c23c-a1dcf7ae0388"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-33900ec1e46a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNaiveBayes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabelCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeaturesCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"features\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodelType\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"multinomial\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcreate_nb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb_tweets_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m.8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mcreate_nb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb_opt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m.8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-25-e4c0dbcd433f>\u001b[0m in \u001b[0;36mcreate_nb\u001b[0;34m(tweets_df, attempt_num, model, train_size)\u001b[0m\n\u001b[1;32m     17\u001b[0m   \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetOrCreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m   \u001b[0msqlContext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSQLContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m   \u001b[0mspark_tweets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msqlContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreateDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweets_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-3.2.3-bin-hadoop2.7/python/pyspark/sql/context.py\u001b[0m in \u001b[0;36mcreateDataFrame\u001b[0;34m(self, data, schema, samplingRatio, verifySchema)\u001b[0m\n\u001b[1;32m    371\u001b[0m         \u001b[0mPy4JJavaError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m         \"\"\"\n\u001b[0;32m--> 373\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparkSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreateDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamplingRatio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverifySchema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregisterDataFrameAsTable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtableName\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-3.2.3-bin-hadoop2.7/python/pyspark/sql/session.py\u001b[0m in \u001b[0;36mcreateDataFrame\u001b[0;34m(self, data, schema, samplingRatio, verifySchema)\u001b[0m\n\u001b[1;32m    671\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhas_pandas\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m             \u001b[0;31m# Create a DataFrame from pandas DataFrame.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m             return super(SparkSession, self).createDataFrame(\n\u001b[0m\u001b[1;32m    674\u001b[0m                 data, schema, samplingRatio, verifySchema)\n\u001b[1;32m    675\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamplingRatio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverifySchema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-3.2.3-bin-hadoop2.7/python/pyspark/sql/pandas/conversion.py\u001b[0m in \u001b[0;36mcreateDataFrame\u001b[0;34m(self, data, schema, samplingRatio, verifySchema)\u001b[0m\n\u001b[1;32m    338\u001b[0m                     \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_from_pandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimezone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamplingRatio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverifySchema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_convert_from_pandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimezone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-3.2.3-bin-hadoop2.7/python/pyspark/sql/session.py\u001b[0m in \u001b[0;36m_create_dataframe\u001b[0;34m(self, data, schema, samplingRatio, verifySchema)\u001b[0m\n\u001b[1;32m    698\u001b[0m             \u001b[0mrdd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_createFromRDD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprepare\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamplingRatio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 700\u001b[0;31m             \u001b[0mrdd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_createFromLocal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprepare\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    701\u001b[0m         \u001b[0mjrdd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSerDeUtil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoJavaArray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_to_java_object_rdd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0mjdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsparkSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplySchemaToPythonRDD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-3.2.3-bin-hadoop2.7/python/pyspark/sql/session.py\u001b[0m in \u001b[0;36m_createFromLocal\u001b[0;34m(self, data, schema)\u001b[0m\n\u001b[1;32m    510\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mschema\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 512\u001b[0;31m             \u001b[0mstruct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inferSchemaFromList\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    513\u001b[0m             \u001b[0mconverter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_create_converter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstruct\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconverter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-3.2.3-bin-hadoop2.7/python/pyspark/sql/session.py\u001b[0m in \u001b[0;36m_inferSchemaFromList\u001b[0;34m(self, data, names)\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"can not infer schema from empty dataset\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m         \u001b[0mschema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_merge_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_infer_schema\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_has_nulltype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Some of types cannot be determined after inferring\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-3.2.3-bin-hadoop2.7/python/pyspark/sql/types.py\u001b[0m in \u001b[0;36m_merge_type\u001b[0;34m(a, b, name)\u001b[0m\n\u001b[1;32m   1107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mStructType\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m         \u001b[0mnfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataType\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfields\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1109\u001b[0;31m         fields = [StructField(f.name, _merge_type(f.dataType, nfs.get(f.name, NullType()),\n\u001b[0m\u001b[1;32m   1110\u001b[0m                                                   name=new_name(f.name)))\n\u001b[1;32m   1111\u001b[0m                   for f in a.fields]\n",
            "\u001b[0;32m/content/spark-3.2.3-bin-hadoop2.7/python/pyspark/sql/types.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mStructType\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m         \u001b[0mnfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataType\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfields\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1109\u001b[0;31m         fields = [StructField(f.name, _merge_type(f.dataType, nfs.get(f.name, NullType()),\n\u001b[0m\u001b[1;32m   1110\u001b[0m                                                   name=new_name(f.name)))\n\u001b[1;32m   1111\u001b[0m                   for f in a.fields]\n",
            "\u001b[0;32m/content/spark-3.2.3-bin-hadoop2.7/python/pyspark/sql/types.py\u001b[0m in \u001b[0;36m_merge_type\u001b[0;34m(a, b, name)\u001b[0m\n\u001b[1;32m   1102\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# TODO: type cast (such as int -> long)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1104\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_msg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Can not merge type %s and %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1106\u001b[0m     \u001b[0;31m# same type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: field text: Can not merge type <class 'pyspark.sql.types.StringType'> and <class 'pyspark.sql.types.DoubleType'>"
          ]
        }
      ],
      "source": [
        "nb = NaiveBayes(labelCol=\"label\", featuresCol=\"features\", modelType=\"multinomial\")\n",
        "create_nb(nb_tweets_df,1,nb,.8)\n",
        "create_nb(nb_opt,2,nb,.8)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}