{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88a4ab07",
   "metadata": {},
   "source": [
    "# Sentiment Analysis of Tweets Dataset using the following Machine Learning models\n",
    "- Logistic Regression\n",
    "- Random Forest Classifier\n",
    "- Extra Trees Classifier\n",
    "- Ada Boost Classifier\n",
    "- Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f965746",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98da782e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\apfle\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\apfle\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\apfle\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\apfle\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# download punctuation and stopwords from nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c986391",
   "metadata": {},
   "source": [
    "# Transform the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c503a564",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27476</th>\n",
       "      <td>4eac33d1c0</td>\n",
       "      <td>wish we could come see u on Denver  husband l...</td>\n",
       "      <td>d lost</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27477</th>\n",
       "      <td>4f4c4fc327</td>\n",
       "      <td>I`ve wondered about rake to.  The client has ...</td>\n",
       "      <td>, don`t force</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27478</th>\n",
       "      <td>f67aae2310</td>\n",
       "      <td>Yay good for both of you. Enjoy the break - y...</td>\n",
       "      <td>Yay good for both of you.</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27479</th>\n",
       "      <td>ed167662a5</td>\n",
       "      <td>But it was worth it  ****.</td>\n",
       "      <td>But it was worth it  ****.</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27480</th>\n",
       "      <td>6f7127d9d7</td>\n",
       "      <td>All this flirting going on - The ATG smiles...</td>\n",
       "      <td>All this flirting going on - The ATG smiles. Y...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27481 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           textID                                               text  \\\n",
       "0      cb774db0d1                I`d have responded, if I were going   \n",
       "1      549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
       "2      088c60f138                          my boss is bullying me...   \n",
       "3      9642c003ef                     what interview! leave me alone   \n",
       "4      358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
       "...           ...                                                ...   \n",
       "27476  4eac33d1c0   wish we could come see u on Denver  husband l...   \n",
       "27477  4f4c4fc327   I`ve wondered about rake to.  The client has ...   \n",
       "27478  f67aae2310   Yay good for both of you. Enjoy the break - y...   \n",
       "27479  ed167662a5                         But it was worth it  ****.   \n",
       "27480  6f7127d9d7     All this flirting going on - The ATG smiles...   \n",
       "\n",
       "                                           selected_text sentiment  \n",
       "0                    I`d have responded, if I were going   neutral  \n",
       "1                                               Sooo SAD  negative  \n",
       "2                                            bullying me  negative  \n",
       "3                                         leave me alone  negative  \n",
       "4                                          Sons of ****,  negative  \n",
       "...                                                  ...       ...  \n",
       "27476                                             d lost  negative  \n",
       "27477                                      , don`t force  negative  \n",
       "27478                          Yay good for both of you.  positive  \n",
       "27479                         But it was worth it  ****.  positive  \n",
       "27480  All this flirting going on - The ATG smiles. Y...   neutral  \n",
       "\n",
       "[27481 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load tweets_df and view\n",
    "tweets_df = pd.read_csv(\"Resources/Tweets.csv\")\n",
    "tweets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c311757b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dataframe ready for processing\n",
    "\n",
    "# make sure the tweets in column \"text\" are strings\n",
    "tweets_df['text'] = tweets_df['text'].astype('str')\n",
    "\n",
    "# delete the unneccessary columns\n",
    "tweets_df = tweets_df.drop(columns=[\"textID\", \"selected_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47021da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_tweets(tweet):\n",
    "    # make the text all lowercase\n",
    "    tweet = tweet.lower()\n",
    "    \n",
    "    # remove punctuation\n",
    "    tweet = \"\".join(char for char in tweet if char not in string.punctuation)\n",
    "    \n",
    "    # tokenize the tweet for url clean\n",
    "    tokenize_tweet_url = word_tokenize(tweet)\n",
    "    \n",
    "    # remove urls\n",
    "    tokenize_tweet_url = \" \".join([i for i in tokenize_tweet_url if 'http' not in i])\n",
    "    \n",
    "    # tokenize the tweet\n",
    "    tokenize_tweets = word_tokenize(tokenize_tweet_url)\n",
    "    \n",
    "    # remove stopwords\n",
    "    stopword = stopwords.words(\"english\")\n",
    "    tweet_wo_stop = [word for word in tokenize_tweets if word not in stopword]\n",
    "    \n",
    "    # lemmatization\n",
    "    lemm = WordNetLemmatizer()\n",
    "    lemmed = [lemm.lemmatize(word) for word in tweet_wo_stop]\n",
    "    \n",
    "    # put string together\n",
    "    final_tweet = \" \".join(lemmed)\n",
    "    \n",
    "    return final_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8616da88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id responded going</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sooo sad miss san diego</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bos bullying</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>interview leave alone</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>son couldnt put release already bought</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     text sentiment\n",
       "0                      id responded going   neutral\n",
       "1                 sooo sad miss san diego  negative\n",
       "2                            bos bullying  negative\n",
       "3                   interview leave alone  negative\n",
       "4  son couldnt put release already bought  negative"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# process tweets using above function\n",
    "tweets_df['text'] = tweets_df['text'].apply(lambda x: process_tweets(x))\n",
    "tweets_df = tweets_df.dropna()\n",
    "\n",
    "# view updated dataframe\n",
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2da464f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='sentiment'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize distribution\n",
    "tweets_df.sentiment.value_counts().plot(kind='pie', autopct='%1.0f%%', colors=['blue', 'gold', 'red'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa959b52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id responded going</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sooo sad miss san diego</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bos bullying</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>interview leave alone</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>son couldnt put release already bought</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     text  sentiment\n",
       "0                      id responded going          0\n",
       "1                 sooo sad miss san diego         -1\n",
       "2                            bos bullying         -1\n",
       "3                   interview leave alone         -1\n",
       "4  son couldnt put release already bought         -1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform the sentiment column into numbers\n",
    "dict_sentiment = {'positive': 1, 'neutral': 0, 'negative': -1}\n",
    "tweets_df['sentiment'] = tweets_df['sentiment'].apply(lambda x: dict_sentiment.get(x))\n",
    "\n",
    "# view updated dataframe\n",
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c926d3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a separate data frame without neutral tweets\n",
    "tweets_no_neut = tweets_df[tweets_df[\"sentiment\"] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b6c50e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='sentiment'>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize distribution - without neutral sentiment\n",
    "tweets_no_neut.sentiment.value_counts().plot(kind='pie', autopct='%1.0f%%', colors=['blue', 'gold', 'red'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f0280c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the X and y data \n",
    "def create_train_test_data (tweets_df, train_size):\n",
    "    \n",
    "    # assign X and y to the input and target columns\n",
    "    X = tweets_df['text']\n",
    "    y = tweets_df['sentiment']\n",
    "\n",
    "    # split the data into testing data and training data\n",
    "    if train_size == 0:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "    else:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=train_size)\n",
    "\n",
    "    # transform the data into tfidf vectors\n",
    "    # fit the tfidf vectorizer on the training data to avoid bias\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "    X_test_tfidf = vectorizer.transform(X_test)\n",
    "    \n",
    "    return X_train_tfidf, X_test_tfidf, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "91767a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model\n",
    "def create_model(tweets_df, attempt_num, model, train_size):\n",
    "    # Get the train and test data\n",
    "    \n",
    "    X_train_tfidf, X_test_tfidf, y_train, y_test = create_train_test_data (tweets_df, train_size)\n",
    "\n",
    "    # create a logistic regression model and fit it to the training data\n",
    "    \n",
    "    model.fit(X_train_tfidf, y_train)\n",
    "    training_score, testing_score = evaluate(model, X_train_tfidf, y_train, X_test_tfidf, y_test, attempt_num)\n",
    "    \n",
    "    return training_score, testing_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0219b4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "def evaluate(model, X_train_tfidf, y_train, X_test_tfidf, y_test, attempt_num):\n",
    "    \n",
    "    training_score = model.score(X_train_tfidf, y_train)\n",
    "    testing_score = model.score(X_test_tfidf, y_test)\n",
    "    \n",
    "    # look at the scores for the testing and training data\n",
    "    print(f\"Attempt {attempt_num} ----------------------------------------\")\n",
    "    print(f\"Training Data Score: {model.score(X_train_tfidf, y_train)}\")\n",
    "    print(f\"Testing Data Score: {model.score(X_test_tfidf, y_test)} \\n\")\n",
    "\n",
    "    # find metrics for testing data\n",
    "    print(confusion_matrix(y_test.values, model.predict(X_test_tfidf)))\n",
    "    print(classification_report(y_test.values, model.predict(X_test_tfidf)))\n",
    "    \n",
    "    return training_score, testing_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "06b6fdc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Attempt Number</th>\n",
       "      <th>Training Score</th>\n",
       "      <th>Testing Score</th>\n",
       "      <th>Parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Model, Attempt Number, Training Score, Testing Score, Parameters]\n",
       "Index: []"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create dataframe for attempts\n",
    "performance_df = pd.DataFrame(columns=[\"Model\", \"Attempt Number\", \"Training Score\", \"Testing Score\", \"Parameters\"])\n",
    "performance_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7252b265",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c056cb6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\apfle\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt 1 ----------------------------------------\n",
      "Training Data Score: 0.8210092188258127\n",
      "Testing Data Score: 0.6888371416096638 \n",
      "\n",
      "[[1162  684  118]\n",
      " [ 359 2123  332]\n",
      " [  82  563 1448]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.72      0.59      0.65      1964\n",
      "           0       0.63      0.75      0.69      2814\n",
      "           1       0.76      0.69      0.73      2093\n",
      "\n",
      "    accuracy                           0.69      6871\n",
      "   macro avg       0.71      0.68      0.69      6871\n",
      "weighted avg       0.70      0.69      0.69      6871\n",
      "\n",
      "Attempt 2 ----------------------------------------\n",
      "Training Data Score: 0.932529335071708\n",
      "Testing Data Score: 0.8670251772182841 \n",
      "\n",
      "[[1701  268]\n",
      " [ 276 1846]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.86      0.86      0.86      1969\n",
      "           1       0.87      0.87      0.87      2122\n",
      "\n",
      "    accuracy                           0.87      4091\n",
      "   macro avg       0.87      0.87      0.87      4091\n",
      "weighted avg       0.87      0.87      0.87      4091\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "\n",
    "training_score, testing_score = create_model(tweets_df, 1, model, 0)\n",
    "\n",
    "# add to performance dataframe\n",
    "performance_df.loc[len(performance_df.index)] = ['Logistic Regression', 1, training_score, testing_score, 'including neutrals']\n",
    "\n",
    "training_score, testing_score = create_model(tweets_no_neut, 2, model, 0)\n",
    "\n",
    "# add to performance dataframe\n",
    "performance_df.loc[len(performance_df.index)] = ['Logistic Regression', 2, training_score, testing_score, 'excluding neutrals']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0cc89740",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Attempt Number</th>\n",
       "      <th>Training Score</th>\n",
       "      <th>Testing Score</th>\n",
       "      <th>Parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>1</td>\n",
       "      <td>0.821009</td>\n",
       "      <td>0.688837</td>\n",
       "      <td>including neutrals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>2</td>\n",
       "      <td>0.932529</td>\n",
       "      <td>0.867025</td>\n",
       "      <td>excluding neutrals</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Attempt Number  Training Score  Testing Score  \\\n",
       "0  Logistic Regression               1        0.821009       0.688837   \n",
       "1  Logistic Regression               2        0.932529       0.867025   \n",
       "\n",
       "           Parameters  \n",
       "0  including neutrals  \n",
       "1  excluding neutrals  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b194d5d2",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "31875fa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt 1 ----------------------------------------\n",
      "Training Data Score: 0.9973617176128093\n",
      "Testing Data Score: 0.7023831180643988 \n",
      "\n",
      "[[ 853  518  108]\n",
      " [ 256 1726  306]\n",
      " [  68  380 1282]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.72      0.58      0.64      1479\n",
      "           0       0.66      0.75      0.70      2288\n",
      "           1       0.76      0.74      0.75      1730\n",
      "\n",
      "    accuracy                           0.70      5497\n",
      "   macro avg       0.71      0.69      0.70      5497\n",
      "weighted avg       0.71      0.70      0.70      5497\n",
      "\n",
      "Attempt 2 ----------------------------------------\n",
      "Training Data Score: 0.9995416348357525\n",
      "Testing Data Score: 0.8472349526428353 \n",
      "\n",
      "[[1345  210]\n",
      " [ 290 1428]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.82      0.86      0.84      1555\n",
      "           1       0.87      0.83      0.85      1718\n",
      "\n",
      "    accuracy                           0.85      3273\n",
      "   macro avg       0.85      0.85      0.85      3273\n",
      "weighted avg       0.85      0.85      0.85      3273\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "twitter_classi = RandomForestClassifier(n_estimators=300, random_state=0)\n",
    "\n",
    "training_score, testing_score = create_model(tweets_df, 1, twitter_classi, train_size=.8)\n",
    "performance_df.loc[len(performance_df.index)] = ['Random Forest', 1, training_score, testing_score, 'including neutrals']\n",
    "\n",
    "training_score, testing_score = create_model(tweets_no_neut, 2, twitter_classi, train_size=.8)\n",
    "performance_df.loc[len(performance_df.index)] = ['Random Forest', 2, training_score, testing_score, 'excluding neutrals']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a107093b",
   "metadata": {},
   "source": [
    "## Extra Trees Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a1559f69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt 1 ----------------------------------------\n",
      "Training Data Score: 0.9974981804949054\n",
      "Testing Data Score: 0.7096598144442423 \n",
      "\n",
      "[[ 949  495  109]\n",
      " [ 262 1660  281]\n",
      " [  60  389 1292]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.75      0.61      0.67      1553\n",
      "           0       0.65      0.75      0.70      2203\n",
      "           1       0.77      0.74      0.75      1741\n",
      "\n",
      "    accuracy                           0.71      5497\n",
      "   macro avg       0.72      0.70      0.71      5497\n",
      "weighted avg       0.72      0.71      0.71      5497\n",
      "\n",
      "Attempt 2 ----------------------------------------\n",
      "Training Data Score: 0.9995416348357525\n",
      "Testing Data Score: 0.8646501680415521 \n",
      "\n",
      "[[1363  187]\n",
      " [ 256 1467]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.84      0.88      0.86      1550\n",
      "           1       0.89      0.85      0.87      1723\n",
      "\n",
      "    accuracy                           0.86      3273\n",
      "   macro avg       0.86      0.87      0.86      3273\n",
      "weighted avg       0.87      0.86      0.86      3273\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "twitter_ex = ExtraTreesClassifier(random_state=1)\n",
    "\n",
    "training_score, testing_score = create_model(tweets_df, 1, twitter_ex, train_size=.8)\n",
    "performance_df.loc[len(performance_df.index)] = ['Extreme Trees', 1, training_score, testing_score, 'including neutrals']\n",
    "\n",
    "training_score, testing_score = create_model(tweets_no_neut, 2, twitter_ex, train_size=.8)\n",
    "performance_df.loc[len(performance_df.index)] = ['Extreme Trees', 2, training_score, testing_score, 'excluding neutrals']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0002db64",
   "metadata": {},
   "source": [
    "## Ada Boost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "772d9f0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt 1 ----------------------------------------\n",
      "Training Data Score: 0.6552492721979621\n",
      "Testing Data Score: 0.6539930871384392 \n",
      "\n",
      "[[ 650  809   98]\n",
      " [ 191 1840  258]\n",
      " [  43  503 1105]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.74      0.42      0.53      1557\n",
      "           0       0.58      0.80      0.68      2289\n",
      "           1       0.76      0.67      0.71      1651\n",
      "\n",
      "    accuracy                           0.65      5497\n",
      "   macro avg       0.69      0.63      0.64      5497\n",
      "weighted avg       0.68      0.65      0.65      5497\n",
      "\n",
      "Attempt 2 ----------------------------------------\n",
      "Training Data Score: 0.806646294881589\n",
      "Testing Data Score: 0.8050717995722578 \n",
      "\n",
      "[[1426  143]\n",
      " [ 495 1209]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.74      0.91      0.82      1569\n",
      "           1       0.89      0.71      0.79      1704\n",
      "\n",
      "    accuracy                           0.81      3273\n",
      "   macro avg       0.82      0.81      0.80      3273\n",
      "weighted avg       0.82      0.81      0.80      3273\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "twitter_ada = AdaBoostClassifier(random_state=1)\n",
    "\n",
    "training_score, testing_score = create_model(tweets_df, 1, twitter_ada, train_size=.8)\n",
    "performance_df.loc[len(performance_df.index)] = ['Ada Boost', 1, training_score, testing_score, 'including neutrals']\n",
    "\n",
    "training_score, testing_score = create_model(tweets_no_neut, 2, twitter_ada, train_size=.8)\n",
    "performance_df.loc[len(performance_df.index)] = ['Ada Boost', 2, training_score, testing_score, 'excluding neutrals']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0a8d834c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Attempt Number</th>\n",
       "      <th>Training Score</th>\n",
       "      <th>Testing Score</th>\n",
       "      <th>Parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>1</td>\n",
       "      <td>0.821009</td>\n",
       "      <td>0.688837</td>\n",
       "      <td>including neutrals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>2</td>\n",
       "      <td>0.932529</td>\n",
       "      <td>0.867025</td>\n",
       "      <td>excluding neutrals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>1</td>\n",
       "      <td>0.997362</td>\n",
       "      <td>0.702383</td>\n",
       "      <td>including neutrals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>2</td>\n",
       "      <td>0.999542</td>\n",
       "      <td>0.847235</td>\n",
       "      <td>excluding neutrals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Extreme Trees</td>\n",
       "      <td>1</td>\n",
       "      <td>0.997498</td>\n",
       "      <td>0.709660</td>\n",
       "      <td>including neutrals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Extreme Trees</td>\n",
       "      <td>2</td>\n",
       "      <td>0.999542</td>\n",
       "      <td>0.864650</td>\n",
       "      <td>excluding neutrals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ada Boost</td>\n",
       "      <td>1</td>\n",
       "      <td>0.655249</td>\n",
       "      <td>0.653993</td>\n",
       "      <td>including neutrals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ada Boost</td>\n",
       "      <td>2</td>\n",
       "      <td>0.806646</td>\n",
       "      <td>0.805072</td>\n",
       "      <td>excluding neutrals</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Attempt Number  Training Score  Testing Score  \\\n",
       "0  Logistic Regression               1        0.821009       0.688837   \n",
       "1  Logistic Regression               2        0.932529       0.867025   \n",
       "2        Random Forest               1        0.997362       0.702383   \n",
       "3        Random Forest               2        0.999542       0.847235   \n",
       "4        Extreme Trees               1        0.997498       0.709660   \n",
       "5        Extreme Trees               2        0.999542       0.864650   \n",
       "6            Ada Boost               1        0.655249       0.653993   \n",
       "7            Ada Boost               2        0.806646       0.805072   \n",
       "\n",
       "           Parameters  \n",
       "0  including neutrals  \n",
       "1  excluding neutrals  \n",
       "2  including neutrals  \n",
       "3  excluding neutrals  \n",
       "4  including neutrals  \n",
       "5  excluding neutrals  \n",
       "6  including neutrals  \n",
       "7  excluding neutrals  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25a8104",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8dfd0224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt 1 ----------------------------------------\n",
      "Training Data Score: 0.7912572780203785\n",
      "Testing Data Score: 0.6090594869929052 \n",
      "\n",
      "[[ 596  931   82]\n",
      " [ 127 1795  227]\n",
      " [  34  748  957]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.79      0.37      0.50      1609\n",
      "           0       0.52      0.84      0.64      2149\n",
      "           1       0.76      0.55      0.64      1739\n",
      "\n",
      "    accuracy                           0.61      5497\n",
      "   macro avg       0.69      0.59      0.59      5497\n",
      "weighted avg       0.67      0.61      0.60      5497\n",
      "\n",
      "Attempt 2 ----------------------------------------\n",
      "Training Data Score: 0.9411764705882353\n",
      "Testing Data Score: 0.8567063855789795 \n",
      "\n",
      "[[1254  299]\n",
      " [ 170 1550]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.88      0.81      0.84      1553\n",
      "           1       0.84      0.90      0.87      1720\n",
      "\n",
      "    accuracy                           0.86      3273\n",
      "   macro avg       0.86      0.85      0.86      3273\n",
      "weighted avg       0.86      0.86      0.86      3273\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "mnb = MultinomialNB()\n",
    "\n",
    "training_score, testing_score = create_model(tweets_df,1,mnb,train_size=0.8)\n",
    "performance_df.loc[len(performance_df.index)] = ['Multinomial Naive Bayes', 1, training_score, testing_score, 'including neutrals']\n",
    "\n",
    "training_score, testing_score = create_model(tweets_no_neut,2,mnb,train_size=0.8)\n",
    "performance_df.loc[len(performance_df.index)] = ['Multinomial Naive Bayes', 2, training_score, testing_score, 'excluding neutrals']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6e04f144",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Attempt Number</th>\n",
       "      <th>Training Score</th>\n",
       "      <th>Testing Score</th>\n",
       "      <th>Parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>1</td>\n",
       "      <td>0.821009</td>\n",
       "      <td>0.688837</td>\n",
       "      <td>including neutrals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>2</td>\n",
       "      <td>0.932529</td>\n",
       "      <td>0.867025</td>\n",
       "      <td>excluding neutrals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>1</td>\n",
       "      <td>0.997362</td>\n",
       "      <td>0.702383</td>\n",
       "      <td>including neutrals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>2</td>\n",
       "      <td>0.999542</td>\n",
       "      <td>0.847235</td>\n",
       "      <td>excluding neutrals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Extreme Trees</td>\n",
       "      <td>1</td>\n",
       "      <td>0.997498</td>\n",
       "      <td>0.709660</td>\n",
       "      <td>including neutrals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Extreme Trees</td>\n",
       "      <td>2</td>\n",
       "      <td>0.999542</td>\n",
       "      <td>0.864650</td>\n",
       "      <td>excluding neutrals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ada Boost</td>\n",
       "      <td>1</td>\n",
       "      <td>0.655249</td>\n",
       "      <td>0.653993</td>\n",
       "      <td>including neutrals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ada Boost</td>\n",
       "      <td>2</td>\n",
       "      <td>0.806646</td>\n",
       "      <td>0.805072</td>\n",
       "      <td>excluding neutrals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Multinomial Naive Bayes</td>\n",
       "      <td>1</td>\n",
       "      <td>0.791257</td>\n",
       "      <td>0.609059</td>\n",
       "      <td>including neutrals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Multinomial Naive Bayes</td>\n",
       "      <td>2</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.856706</td>\n",
       "      <td>excluding neutrals</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Model  Attempt Number  Training Score  Testing Score  \\\n",
       "0      Logistic Regression               1        0.821009       0.688837   \n",
       "1      Logistic Regression               2        0.932529       0.867025   \n",
       "2            Random Forest               1        0.997362       0.702383   \n",
       "3            Random Forest               2        0.999542       0.847235   \n",
       "4            Extreme Trees               1        0.997498       0.709660   \n",
       "5            Extreme Trees               2        0.999542       0.864650   \n",
       "6                Ada Boost               1        0.655249       0.653993   \n",
       "7                Ada Boost               2        0.806646       0.805072   \n",
       "8  Multinomial Naive Bayes               1        0.791257       0.609059   \n",
       "9  Multinomial Naive Bayes               2        0.941176       0.856706   \n",
       "\n",
       "           Parameters  \n",
       "0  including neutrals  \n",
       "1  excluding neutrals  \n",
       "2  including neutrals  \n",
       "3  excluding neutrals  \n",
       "4  including neutrals  \n",
       "5  excluding neutrals  \n",
       "6  including neutrals  \n",
       "7  excluding neutrals  \n",
       "8  including neutrals  \n",
       "9  excluding neutrals  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa9a461",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
